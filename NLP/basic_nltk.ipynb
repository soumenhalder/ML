{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Install and download package from the nltk](#toc1_1_)    \n",
    "  - [Laod the packages](#toc1_2_)    \n",
    "  - [Load some corpus and check these packages](#toc1_3_)    \n",
    "    - [tokenize the paragraph](#toc1_3_1_)    \n",
    "    - [word tokenize](#toc1_3_2_)    \n",
    "    - [Remove the stop words](#toc1_3_3_)    \n",
    "    - [Apply stemming and lemmatization](#toc1_3_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Install and download package from the nltk](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/soumen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/soumen/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/soumen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/soumen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Laod the packages](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming \n",
    "from nltk.stem import PorterStemmer\n",
    "# lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# stop words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Load some corpus and check these packages](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"The World Economic Forum\n",
    "said an investigation into\n",
    "founder Klaus Schwab found\n",
    "minor expense irregularities\n",
    "but no material wrongdoing.\n",
    "The Davos conference orga-\n",
    "nizer also said it was shuffling\n",
    "the leadership of its board in\n",
    "the wake of the probe.\n",
    "The board’s interim chair-\n",
    "man, Peter Brabeck-Letmathe,\n",
    "a former chief executive of\n",
    "Nestlé, resigned after a meet-\n",
    "ing of trustees earlier this\n",
    "week to discuss the probe’s\n",
    "conclusions, according to a\n",
    "letter reviewed by The Wall\n",
    "Street Journal. He raised con-\n",
    "cerns about a “toxic” work en-\n",
    "vironment in his resignation\n",
    "letter, which hasn’t been pre-\n",
    "viously reported.\n",
    "At a meeting on Friday, the\n",
    "Forum appointed two new in-\n",
    "terim co-chairs to steer the\n",
    "board of trustees: BlackRock\n",
    "boss Larry Fink and Swiss bil-\n",
    "lionaire André Hoffmann.\n",
    "The Forum said Friday that\n",
    "the board wants to move on\n",
    "from a dispute with its\n",
    "founder that has roiled the or-\n",
    "ganization. The board said it\n",
    "has concluded “there is no ev-\n",
    "idence of material wrongdo-\n",
    "ing” by Schwab or his wife,\n",
    "Hilde Schwab.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[tokenize the paragraph](#toc0_)\n",
    "\n",
    "* the whole paragraph tokenize to several sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The World Economic Forum said an investigation into founder Klaus Schwab found minor expense irregularities but no material wrongdoing.',\n",
       " 'The Davos conference organizer also said it was shuffling the leadership of its board in the wake of the probe.',\n",
       " 'The board’s interim chairman, Peter Brabeck-Letmathe, a former chief executive of Nestlé, resigned after a meeting of trustees earlier this week to discuss the probe’s conclusions, according to a letter reviewed by The Wall Street Journal.',\n",
       " 'He raised concerns about a “toxic” work environment in his resignation letter, which hasn’t been previously reported.',\n",
       " 'At a meeting on Friday, the Forum appointed two new interim co-chairs to steer the board of trustees: BlackRock boss Larry Fink and Swiss billionaire André Hoffmann.',\n",
       " 'The Forum said Friday that the board wants to move on from a dispute with its founder that has roiled the organization.',\n",
       " 'The board said it has concluded “there is no evidence of material wrongdoing” by Schwab or his wife, Hilde Schwab.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "sentences = [sentence.replace('-\\n', '').replace('\\n', ' ') for sentence in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[word tokenize](#toc0_)\n",
    "\n",
    "* Sentences tokenized to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'World', 'Economic', 'Forum', 'said']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_words = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "tokenized_words[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_3_'></a>[Remove the stop words, lower case](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_sw = []\n",
    "for tokenwor in tokenized_words:\n",
    "    sen = []\n",
    "    [sen.append(w.lower()) for w in tokenwor if w not in stopwords.words('english') and w not in ['.', ',', \"\\\"\"]]\n",
    "    removed_sw.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words reduced from 20 to 15 in sentence 0\n",
      "Number of words reduced from 21 to 11 in sentence 1\n",
      "Number of words reduced from 45 to 27 in sentence 2\n",
      "Number of words reduced from 23 to 13 in sentence 3\n",
      "Number of words reduced from 30 to 21 in sentence 4\n",
      "Number of words reduced from 23 to 11 in sentence 5\n",
      "Number of words reduced from 24 to 13 in sentence 6\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokenized_words)):\n",
    "    print(f\"Number of words reduced from {len(tokenized_words[i])} to {len(removed_sw[i])} in sentence {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Davos', 'conference', 'organizer', 'also', 'said', 'it', 'was', 'shuffling', 'the', 'leadership', 'of', 'its', 'board', 'in', 'the', 'wake', 'of', 'the', 'probe', '.'] \n",
      " ['the', 'davos', 'conference', 'organizer', 'also', 'said', 'shuffling', 'leadership', 'board', 'wake', 'probe']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_words[1],'\\n',removed_sw[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_4_'></a>[Apply stemming and lemmatization](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "lematizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histor'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple example of stemming\n",
    "stemmer.stem('historical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'historical'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple example of lematizer\n",
    "lematizer.lemmatize('historical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'world', 'economic', 'forum', 'said', 'investigation', 'founder', 'klaus', 'schwab', 'found', 'minor', 'expense', 'irregularities', 'material', 'wrongdoing']\n",
      "['the', 'davos', 'conference', 'organizer', 'also', 'said', 'shuffling', 'leadership', 'board', 'wake', 'probe']\n",
      "['the', 'board', '’', 'interim', 'chairman', 'peter', 'brabeck-letmathe', 'former', 'chief', 'executive', 'nestlé', 'resigned', 'meeting', 'trustees', 'earlier', 'week', 'discuss', 'probe', '’', 'conclusions', 'according', 'letter', 'reviewed', 'the', 'wall', 'street', 'journal']\n",
      "['he', 'raised', 'concerns', '“', 'toxic', '”', 'work', 'environment', 'resignation', 'letter', '’', 'previously', 'reported']\n",
      "['at', 'meeting', 'friday', 'forum', 'appointed', 'two', 'new', 'interim', 'co-chairs', 'steer', 'board', 'trustees', ':', 'blackrock', 'boss', 'larry', 'fink', 'swiss', 'billionaire', 'andré', 'hoffmann']\n",
      "['the', 'forum', 'said', 'friday', 'board', 'wants', 'move', 'dispute', 'founder', 'roiled', 'organization']\n",
      "['the', 'board', 'said', 'concluded', '“', 'evidence', 'material', 'wrongdoing', '”', 'schwab', 'wife', 'hilde', 'schwab']\n"
     ]
    }
   ],
   "source": [
    "for tokenwor in removed_sw:\n",
    "    print(tokenwor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the(the, the), world(world, world), economic(econom, economic), forum(forum, forum), said(said, said), investigation(investig, investigation), founder(founder, founder), klaus(klau, klaus), schwab(schwab, schwab), found(found, found), minor(minor, minor), expense(expens, expense), irregularities(irregular, irregularity), material(materi, material), wrongdoing(wrongdo, wrongdoing), \n",
      "\n",
      "the(the, the), davos(davo, davos), conference(confer, conference), organizer(organ, organizer), also(also, also), said(said, said), shuffling(shuffl, shuffling), leadership(leadership, leadership), board(board, board), wake(wake, wake), probe(probe, probe), \n",
      "\n",
      "the(the, the), board(board, board), ’(’, ’), interim(interim, interim), chairman(chairman, chairman), peter(peter, peter), brabeck-letmathe(brabeck-letmath, brabeck-letmathe), former(former, former), chief(chief, chief), executive(execut, executive), nestlé(nestlé, nestlé), resigned(resign, resigned), meeting(meet, meeting), trustees(truste, trustee), earlier(earlier, earlier), week(week, week), discuss(discuss, discus), probe(probe, probe), ’(’, ’), conclusions(conclus, conclusion), according(accord, according), letter(letter, letter), reviewed(review, reviewed), the(the, the), wall(wall, wall), street(street, street), journal(journal, journal), \n",
      "\n",
      "he(he, he), raised(rais, raised), concerns(concern, concern), “(“, “), toxic(toxic, toxic), ”(”, ”), work(work, work), environment(environ, environment), resignation(resign, resignation), letter(letter, letter), ’(’, ’), previously(previous, previously), reported(report, reported), \n",
      "\n",
      "at(at, at), meeting(meet, meeting), friday(friday, friday), forum(forum, forum), appointed(appoint, appointed), two(two, two), new(new, new), interim(interim, interim), co-chairs(co-chair, co-chairs), steer(steer, steer), board(board, board), trustees(truste, trustee), :(:, :), blackrock(blackrock, blackrock), boss(boss, bos), larry(larri, larry), fink(fink, fink), swiss(swiss, swiss), billionaire(billionair, billionaire), andré(andré, andré), hoffmann(hoffmann, hoffmann), \n",
      "\n",
      "the(the, the), forum(forum, forum), said(said, said), friday(friday, friday), board(board, board), wants(want, want), move(move, move), dispute(disput, dispute), founder(founder, founder), roiled(roil, roiled), organization(organ, organization), \n",
      "\n",
      "the(the, the), board(board, board), said(said, said), concluded(conclud, concluded), “(“, “), evidence(evid, evidence), material(materi, material), wrongdoing(wrongdo, wrongdoing), ”(”, ”), schwab(schwab, schwab), wife(wife, wife), hilde(hild, hilde), schwab(schwab, schwab), \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stemmed = []\n",
    "lemmatized = []\n",
    "for tokenwor in removed_sw:\n",
    "    senstem = []\n",
    "    senlemma = []\n",
    "\n",
    "    for w in tokenwor:\n",
    "        print(f\"{w}({stemmer.stem(w)}, {lematizer.lemmatize(w)})\", end = ', ')\n",
    "        senstem.append(stemmer.stem(w))\n",
    "        senlemma.append(lematizer.lemmatize(w))\n",
    "    stemmed.append(senstem)\n",
    "    lemmatized.append(senlemma)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply all of them together and prepare corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world economic forum said investigation founder klaus schwab found minor expense irregularity material wrongdoing',\n",
       " 'davos conference organizer also said shuffling leadership board wake probe',\n",
       " 'board interim chairman peter brabeckletmathe former chief executive nestl resigned meeting trustee earlier week discus probe conclusion according letter reviewed wall street journal',\n",
       " 'raised concern toxic work environment resignation letter hasnt previously reported',\n",
       " 'meeting friday forum appointed two new interim cochairs steer board trustee blackrock bos larry fink swiss billionaire andr hoffmann',\n",
       " 'forum said friday board want move dispute founder roiled organization',\n",
       " 'board said concluded evidence material wrongdoing schwab wife hilde schwab']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    # clean the text + lower case\n",
    "    review = re.sub(r'[^a-zA-Z\\s]','', sentences[i]).lower()\n",
    "    # remove stop words + lemmatize\n",
    "    review = [lematizer.lemmatize(word) for word in nltk.word_tokenize(review) if word not in stopwords.words\n",
    "    ('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally apply `BAG of words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the word, i.e in the vector 74th dimension is representation of the word 'world', similarly 20th dimension is representation of the word 'econimic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'world': 74,\n",
       " 'economic': 20,\n",
       " 'forum': 27,\n",
       " 'said': 59,\n",
       " 'investigation': 35,\n",
       " 'founder': 29,\n",
       " 'klaus': 38,\n",
       " 'schwab': 60,\n",
       " 'found': 28,\n",
       " 'minor': 44,\n",
       " 'expense': 24,\n",
       " 'irregularity': 36,\n",
       " 'material': 42,\n",
       " 'wrongdoing': 75,\n",
       " 'davos': 16,\n",
       " 'conference': 15,\n",
       " 'organizer': 49,\n",
       " 'also': 1,\n",
       " 'shuffling': 61,\n",
       " 'leadership': 40,\n",
       " 'board': 6,\n",
       " 'wake': 68,\n",
       " 'probe': 52,\n",
       " 'interim': 34,\n",
       " 'chairman': 9,\n",
       " 'peter': 50,\n",
       " 'brabeckletmathe': 8,\n",
       " 'former': 26,\n",
       " 'chief': 10,\n",
       " 'executive': 23,\n",
       " 'nestl': 46,\n",
       " 'resigned': 56,\n",
       " 'meeting': 43,\n",
       " 'trustee': 66,\n",
       " 'earlier': 19,\n",
       " 'week': 71,\n",
       " 'discus': 17,\n",
       " 'conclusion': 14,\n",
       " 'according': 0,\n",
       " 'letter': 41,\n",
       " 'reviewed': 57,\n",
       " 'wall': 69,\n",
       " 'street': 63,\n",
       " 'journal': 37,\n",
       " 'raised': 53,\n",
       " 'concern': 12,\n",
       " 'toxic': 65,\n",
       " 'work': 73,\n",
       " 'environment': 21,\n",
       " 'resignation': 55,\n",
       " 'hasnt': 31,\n",
       " 'previously': 51,\n",
       " 'reported': 54,\n",
       " 'friday': 30,\n",
       " 'appointed': 3,\n",
       " 'two': 67,\n",
       " 'new': 47,\n",
       " 'cochairs': 11,\n",
       " 'steer': 62,\n",
       " 'blackrock': 5,\n",
       " 'bos': 7,\n",
       " 'larry': 39,\n",
       " 'fink': 25,\n",
       " 'swiss': 64,\n",
       " 'billionaire': 4,\n",
       " 'andr': 2,\n",
       " 'hoffmann': 33,\n",
       " 'want': 70,\n",
       " 'move': 45,\n",
       " 'dispute': 18,\n",
       " 'roiled': 58,\n",
       " 'organization': 48,\n",
       " 'concluded': 13,\n",
       " 'evidence': 22,\n",
       " 'wife': 72,\n",
       " 'hilde': 32}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = cv.vocabulary_\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Lets check a sentence and cross check the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'davos conference organizer also said shuffling leadership board wake probe'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  6, 15, 16, 40, 49, 52, 59, 61, 68])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension of the words in corpus[1]\n",
    "\n",
    "import numpy as np\n",
    "x = np.array([vocab[w] for w in  nltk.word_tokenize(corpus[1])])\n",
    "np.sort(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the vector\n",
    "X[1].toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "15\n",
      "16\n",
      "40\n",
      "49\n",
      "52\n",
      "59\n",
      "61\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X[1].toarray()[0])):\n",
    "    if X[1].toarray()[0][i]!=0:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
